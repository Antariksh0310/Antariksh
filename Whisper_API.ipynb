{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMSyicCXmPje1g84NbpjVZX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Antariksh0310/Antariksh/blob/main/Whisper_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transcribe using whisper"
      ],
      "metadata": {
        "id": "L2lqYEJNX7aK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0ihkmAXU3Dq",
        "outputId": "633078e9-5124-4c60-bc15-6719f8500011"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-wasglu03\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-wasglu03\n",
            "  Resolved https://github.com/openai/whisper.git to commit 248b6cb124225dd263bb9bd32d060b6517e067f8\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314) (2.0.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314) (0.56.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314) (1.22.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314) (4.65.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314) (9.1.0)\n",
            "Collecting tiktoken==0.3.3 (from openai-whisper==20230314)\n",
            "  Downloading tiktoken-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.3.3->openai-whisper==20230314) (2022.10.31)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.3.3->openai-whisper==20230314) (2.27.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20230314) (3.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20230314) (3.12.0)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20230314) (16.0.5)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20230314) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20230314) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230314) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230314) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230314) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230314) (3.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230314) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230314) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230314) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230314) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20230314) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20230314) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20230314-py3-none-any.whl size=798075 sha256=4a6ffec8ca27c512a952964a12d023a6daf178a7b053f717c57ca5cc0d3a089e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-irgpaw7a/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: tiktoken, openai-whisper\n",
            "Successfully installed openai-whisper-20230314 tiktoken-0.3.3\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:3 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Get:5 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "Hit:7 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Hit:8 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Get:9 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Hit:10 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1,058 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3,255 kB]\n",
            "Hit:13 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Get:14 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,354 kB]\n",
            "Fetched 6,007 kB in 2s (3,245 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "38 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.2.7-0ubuntu0.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 38 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!sudo apt update && sudo apt install ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "QNACHPa8YVlo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dded37ac-2c24-427f-cc70-33d515915d96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper"
      ],
      "metadata": {
        "id": "-9T2sWOhpK-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper \"/content/wake_up_to_reality.mp4\" --model medium.en"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZW7RTW9bVV_c",
        "outputId": "b954ba9c-106a-47a4-a447-372398b3bc8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|██████████████████████████████████████| 1.42G/1.42G [00:14<00:00, 104MiB/s]\n",
            "[00:00.000 --> 00:20.000]  Wake up to reality. Nothing ever goes as planned in this accursed world. The longer you live the more you will realize that the only things that truly exist in this reality are merely pain, suffering and futility.\n",
            "[00:20.000 --> 00:33.000]  Listen. Everywhere you look in this world wherever there is light there will always be shadows to be found as well. As long as there is a concept of victors the vanquished will also exist.\n",
            "[00:33.000 --> 00:42.000]  The selfish intent of wanting to preserve peace initiates wars and hatred is born in order to protect love.\n",
            "[00:42.000 --> 01:05.000]  There are nexuses, causal relationships that cannot be separated. I want to sever the fate of this world. A world of only victors. A world of only peace. A world of only love. I will create such a world.\n",
            "[01:05.000 --> 01:24.000]  I am the ghost of the Uchiha. For truly this reality is our hell.\n",
            "[01:35.000 --> 01:36.000]  I am the ghost of the Uchiha. For truly this reality is our hell.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/wake_up_to_reality.txt\", \"r\") as file:\n",
        "    content = file.read()\n",
        "    print(content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YW8g_KpFZ_i1",
        "outputId": "6b06941a-8d5c-4393-c2ab-1230ff078c36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "nltk.download('vader_lexicon')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPJoFEarpwMk",
        "outputId": "81a8f1fc-abb8-4737-aca9-d0bb81cf3518"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent= SentimentIntensityAnalyzer()"
      ],
      "metadata": {
        "id": "4j6wMBXAp2_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent.polarity_scores(\"Wake up to reality. Nothing ever goes as planned in this accursed world. The longer you live the more you will realize that the only things that truly exist in this reality are merely pain, suffering and futility.Listen. Everywhere you look in this world wherever there is light there will always be shadows to be found as well. As long as there is a concept of victors the vanquished will also exist.The selfish intent of wanting to preserve peace initiates wars and hatred is born in order to protect love.There are nexuses, causal relationships that cannot be separated. I want to sever the fate of this world. A world of only victors. A world of only peace. A world of only love. I will create such a world.I am the ghost of the Uchiha. For truly this reality is our hell.\")"
      ],
      "metadata": {
        "id": "7XbQgHvMp3IJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77e3d859-0a35-4731-be6f-db6198be3fee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'neg': 0.152, 'neu': 0.706, 'pos': 0.142, 'compound': -0.3863}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper -h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBS2o6M7WRO5",
        "outputId": "43eecfcf-77cb-4528-849e-1300583ff855"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: whisper\n",
            "       [-h]\n",
            "       [--model {tiny.en,tiny,base.en,base,small.en,small,medium.en,medium,large-v1,large-v2,large}]\n",
            "       [--model_dir MODEL_DIR]\n",
            "       [--device DEVICE]\n",
            "       [--output_dir OUTPUT_DIR]\n",
            "       [--output_format {txt,vtt,srt,tsv,json,all}]\n",
            "       [--verbose VERBOSE]\n",
            "       [--task {transcribe,translate}]\n",
            "       [--language {af,am,ar,as,az,ba,be,bg,bn,bo,br,bs,ca,cs,cy,da,de,el,en,es,et,eu,fa,fi,fo,fr,gl,gu,ha,haw,he,hi,hr,ht,hu,hy,id,is,it,ja,jw,ka,kk,km,kn,ko,la,lb,ln,lo,lt,lv,mg,mi,mk,ml,mn,mr,ms,mt,my,ne,nl,nn,no,oc,pa,pl,ps,pt,ro,ru,sa,sd,si,sk,sl,sn,so,sq,sr,su,sv,sw,ta,te,tg,th,tk,tl,tr,tt,uk,ur,uz,vi,yi,yo,zh,Afrikaans,Albanian,Amharic,Arabic,Armenian,Assamese,Azerbaijani,Bashkir,Basque,Belarusian,Bengali,Bosnian,Breton,Bulgarian,Burmese,Castilian,Catalan,Chinese,Croatian,Czech,Danish,Dutch,English,Estonian,Faroese,Finnish,Flemish,French,Galician,Georgian,German,Greek,Gujarati,Haitian,Haitian Creole,Hausa,Hawaiian,Hebrew,Hindi,Hungarian,Icelandic,Indonesian,Italian,Japanese,Javanese,Kannada,Kazakh,Khmer,Korean,Lao,Latin,Latvian,Letzeburgesch,Lingala,Lithuanian,Luxembourgish,Macedonian,Malagasy,Malay,Malayalam,Maltese,Maori,Marathi,Moldavian,Moldovan,Mongolian,Myanmar,Nepali,Norwegian,Nynorsk,Occitan,Panjabi,Pashto,Persian,Polish,Portuguese,Punjabi,Pushto,Romanian,Russian,Sanskrit,Serbian,Shona,Sindhi,Sinhala,Sinhalese,Slovak,Slovenian,Somali,Spanish,Sundanese,Swahili,Swedish,Tagalog,Tajik,Tamil,Tatar,Telugu,Thai,Tibetan,Turkish,Turkmen,Ukrainian,Urdu,Uzbek,Valencian,Vietnamese,Welsh,Yiddish,Yoruba}]\n",
            "       [--temperature TEMPERATURE]\n",
            "       [--best_of BEST_OF]\n",
            "       [--beam_size BEAM_SIZE]\n",
            "       [--patience PATIENCE]\n",
            "       [--length_penalty LENGTH_PENALTY]\n",
            "       [--suppress_tokens SUPPRESS_TOKENS]\n",
            "       [--initial_prompt INITIAL_PROMPT]\n",
            "       [--condition_on_previous_text CONDITION_ON_PREVIOUS_TEXT]\n",
            "       [--fp16 FP16]\n",
            "       [--temperature_increment_on_fallback TEMPERATURE_INCREMENT_ON_FALLBACK]\n",
            "       [--compression_ratio_threshold COMPRESSION_RATIO_THRESHOLD]\n",
            "       [--logprob_threshold LOGPROB_THRESHOLD]\n",
            "       [--no_speech_threshold NO_SPEECH_THRESHOLD]\n",
            "       [--word_timestamps WORD_TIMESTAMPS]\n",
            "       [--prepend_punctuations PREPEND_PUNCTUATIONS]\n",
            "       [--append_punctuations APPEND_PUNCTUATIONS]\n",
            "       [--highlight_words HIGHLIGHT_WORDS]\n",
            "       [--max_line_width MAX_LINE_WIDTH]\n",
            "       [--max_line_count MAX_LINE_COUNT]\n",
            "       [--threads THREADS]\n",
            "       audio\n",
            "       [audio ...]\n",
            "\n",
            "positional arguments:\n",
            "  audio\n",
            "    audio\n",
            "    file(s) to\n",
            "    transcribe\n",
            "\n",
            "options:\n",
            "  -h, --help\n",
            "    show this\n",
            "    help\n",
            "    message and\n",
            "    exit\n",
            "  --model {tiny.en,tiny,base.en,base,small.en,small,medium.en,medium,large-v1,large-v2,large}\n",
            "    name of the\n",
            "    Whisper\n",
            "    model to\n",
            "    use\n",
            "    (default:\n",
            "    small)\n",
            "  --model_dir MODEL_DIR\n",
            "    the path to\n",
            "    save model\n",
            "    files; uses\n",
            "    ~/.cache/wh\n",
            "    isper by\n",
            "    default\n",
            "    (default:\n",
            "    None)\n",
            "  --device DEVICE\n",
            "    device to\n",
            "    use for\n",
            "    PyTorch\n",
            "    inference\n",
            "    (default:\n",
            "    cuda)\n",
            "  --output_dir OUTPUT_DIR, -o OUTPUT_DIR\n",
            "    directory\n",
            "    to save the\n",
            "    outputs\n",
            "    (default:\n",
            "    .)\n",
            "  --output_format {txt,vtt,srt,tsv,json,all}, -f {txt,vtt,srt,tsv,json,all}\n",
            "    format of\n",
            "    the output\n",
            "    file; if\n",
            "    not\n",
            "    specified,\n",
            "    all\n",
            "    available\n",
            "    formats\n",
            "    will be\n",
            "    produced\n",
            "    (default:\n",
            "    all)\n",
            "  --verbose VERBOSE\n",
            "    whether to\n",
            "    print out\n",
            "    the\n",
            "    progress\n",
            "    and debug\n",
            "    messages\n",
            "    (default:\n",
            "    True)\n",
            "  --task {transcribe,translate}\n",
            "    whether to\n",
            "    perform\n",
            "    X->X speech\n",
            "    recognition\n",
            "    ('transcrib\n",
            "    e') or\n",
            "    X->English\n",
            "    translation\n",
            "    ('translate\n",
            "    ')\n",
            "    (default:\n",
            "    transcribe)\n",
            "  --language {af,am,ar,as,az,ba,be,bg,bn,bo,br,bs,ca,cs,cy,da,de,el,en,es,et,eu,fa,fi,fo,fr,gl,gu,ha,haw,he,hi,hr,ht,hu,hy,id,is,it,ja,jw,ka,kk,km,kn,ko,la,lb,ln,lo,lt,lv,mg,mi,mk,ml,mn,mr,ms,mt,my,ne,nl,nn,no,oc,pa,pl,ps,pt,ro,ru,sa,sd,si,sk,sl,sn,so,sq,sr,su,sv,sw,ta,te,tg,th,tk,tl,tr,tt,uk,ur,uz,vi,yi,yo,zh,Afrikaans,Albanian,Amharic,Arabic,Armenian,Assamese,Azerbaijani,Bashkir,Basque,Belarusian,Bengali,Bosnian,Breton,Bulgarian,Burmese,Castilian,Catalan,Chinese,Croatian,Czech,Danish,Dutch,English,Estonian,Faroese,Finnish,Flemish,French,Galician,Georgian,German,Greek,Gujarati,Haitian,Haitian Creole,Hausa,Hawaiian,Hebrew,Hindi,Hungarian,Icelandic,Indonesian,Italian,Japanese,Javanese,Kannada,Kazakh,Khmer,Korean,Lao,Latin,Latvian,Letzeburgesch,Lingala,Lithuanian,Luxembourgish,Macedonian,Malagasy,Malay,Malayalam,Maltese,Maori,Marathi,Moldavian,Moldovan,Mongolian,Myanmar,Nepali,Norwegian,Nynorsk,Occitan,Panjabi,Pashto,Persian,Polish,Portuguese,Punjabi,Pushto,Romanian,Russian,Sanskrit,Serbian,Shona,Sindhi,Sinhala,Sinhalese,Slovak,Slovenian,Somali,Spanish,Sundanese,Swahili,Swedish,Tagalog,Tajik,Tamil,Tatar,Telugu,Thai,Tibetan,Turkish,Turkmen,Ukrainian,Urdu,Uzbek,Valencian,Vietnamese,Welsh,Yiddish,Yoruba}\n",
            "    language\n",
            "    spoken in\n",
            "    the audio,\n",
            "    specify\n",
            "    None to\n",
            "    perform\n",
            "    language\n",
            "    detection\n",
            "    (default:\n",
            "    None)\n",
            "  --temperature TEMPERATURE\n",
            "    temperature\n",
            "    to use for\n",
            "    sampling\n",
            "    (default:\n",
            "    0)\n",
            "  --best_of BEST_OF\n",
            "    number of\n",
            "    candidates\n",
            "    when\n",
            "    sampling\n",
            "    with non-\n",
            "    zero\n",
            "    temperature\n",
            "    (default:\n",
            "    5)\n",
            "  --beam_size BEAM_SIZE\n",
            "    number of\n",
            "    beams in\n",
            "    beam\n",
            "    search,\n",
            "    only\n",
            "    applicable\n",
            "    when\n",
            "    temperature\n",
            "    is zero\n",
            "    (default:\n",
            "    5)\n",
            "  --patience PATIENCE\n",
            "    optional\n",
            "    patience\n",
            "    value to\n",
            "    use in beam\n",
            "    decoding,\n",
            "    as in https\n",
            "    ://arxiv.or\n",
            "    g/abs/2204.\n",
            "    05424, the\n",
            "    default\n",
            "    (1.0) is\n",
            "    equivalent\n",
            "    to conventi\n",
            "    onal beam\n",
            "    search\n",
            "    (default:\n",
            "    None)\n",
            "  --length_penalty LENGTH_PENALTY\n",
            "    optional\n",
            "    token\n",
            "    length\n",
            "    penalty\n",
            "    coefficient\n",
            "    (alpha) as\n",
            "    in https://\n",
            "    arxiv.org/a\n",
            "    bs/1609.081\n",
            "    44, uses\n",
            "    simple\n",
            "    length norm\n",
            "    alization\n",
            "    by default\n",
            "    (default:\n",
            "    None)\n",
            "  --suppress_tokens SUPPRESS_TOKENS\n",
            "    comma-\n",
            "    separated\n",
            "    list of\n",
            "    token ids\n",
            "    to suppress\n",
            "    during\n",
            "    sampling;\n",
            "    '-1' will\n",
            "    suppress\n",
            "    most\n",
            "    special\n",
            "    characters\n",
            "    except\n",
            "    common punc\n",
            "    tuations\n",
            "    (default:\n",
            "    -1)\n",
            "  --initial_prompt INITIAL_PROMPT\n",
            "    optional\n",
            "    text to\n",
            "    provide as\n",
            "    a prompt\n",
            "    for the\n",
            "    first\n",
            "    window.\n",
            "    (default:\n",
            "    None)\n",
            "  --condition_on_previous_text CONDITION_ON_PREVIOUS_TEXT\n",
            "    if True,\n",
            "    provide the\n",
            "    previous\n",
            "    output of\n",
            "    the model\n",
            "    as a prompt\n",
            "    for the\n",
            "    next\n",
            "    window;\n",
            "    disabling\n",
            "    may make\n",
            "    the text in\n",
            "    consistent\n",
            "    across\n",
            "    windows,\n",
            "    but the\n",
            "    model\n",
            "    becomes\n",
            "    less prone\n",
            "    to getting\n",
            "    stuck in a\n",
            "    failure\n",
            "    loop\n",
            "    (default:\n",
            "    True)\n",
            "  --fp16 FP16\n",
            "    whether to\n",
            "    perform\n",
            "    inference\n",
            "    in fp16;\n",
            "    True by\n",
            "    default\n",
            "    (default:\n",
            "    True)\n",
            "  --temperature_increment_on_fallback TEMPERATURE_INCREMENT_ON_FALLBACK\n",
            "    temperature\n",
            "    to increase\n",
            "    when\n",
            "    falling\n",
            "    back when\n",
            "    the\n",
            "    decoding\n",
            "    fails to\n",
            "    meet either\n",
            "    of the\n",
            "    thresholds\n",
            "    below\n",
            "    (default:\n",
            "    0.2)\n",
            "  --compression_ratio_threshold COMPRESSION_RATIO_THRESHOLD\n",
            "    if the gzip\n",
            "    compression\n",
            "    ratio is\n",
            "    higher than\n",
            "    this value,\n",
            "    treat the\n",
            "    decoding as\n",
            "    failed\n",
            "    (default:\n",
            "    2.4)\n",
            "  --logprob_threshold LOGPROB_THRESHOLD\n",
            "    if the\n",
            "    average log\n",
            "    probability\n",
            "    is lower\n",
            "    than this\n",
            "    value,\n",
            "    treat the\n",
            "    decoding as\n",
            "    failed\n",
            "    (default:\n",
            "    -1.0)\n",
            "  --no_speech_threshold NO_SPEECH_THRESHOLD\n",
            "    if the\n",
            "    probability\n",
            "    of the <|no\n",
            "    speech|>\n",
            "    token is\n",
            "    higher than\n",
            "    this value\n",
            "    AND the\n",
            "    decoding\n",
            "    has failed\n",
            "    due to `log\n",
            "    prob_thresh\n",
            "    old`,\n",
            "    consider\n",
            "    the segment\n",
            "    as silence\n",
            "    (default:\n",
            "    0.6)\n",
            "  --word_timestamps WORD_TIMESTAMPS\n",
            "    (experiment\n",
            "    al) extract\n",
            "    word-level\n",
            "    timestamps\n",
            "    and refine\n",
            "    the results\n",
            "    based on\n",
            "    them\n",
            "    (default:\n",
            "    False)\n",
            "  --prepend_punctuations PREPEND_PUNCTUATIONS\n",
            "    if word_tim\n",
            "    estamps is\n",
            "    True, merge\n",
            "    these\n",
            "    punctuation\n",
            "    symbols\n",
            "    with the\n",
            "    next word\n",
            "    (default:\n",
            "    \"'“¿([{-)\n",
            "  --append_punctuations APPEND_PUNCTUATIONS\n",
            "    if word_tim\n",
            "    estamps is\n",
            "    True, merge\n",
            "    these\n",
            "    punctuation\n",
            "    symbols\n",
            "    with the\n",
            "    previous\n",
            "    word\n",
            "    (default: \"\n",
            "    '.。,，!！?？:：\n",
            "    ”)]}、)\n",
            "  --highlight_words HIGHLIGHT_WORDS\n",
            "    (requires -\n",
            "    -word_times\n",
            "    tamps True)\n",
            "    underline\n",
            "    each word\n",
            "    as it is\n",
            "    spoken in\n",
            "    srt and vtt\n",
            "    (default:\n",
            "    False)\n",
            "  --max_line_width MAX_LINE_WIDTH\n",
            "    (requires -\n",
            "    -word_times\n",
            "    tamps True)\n",
            "    the maximum\n",
            "    number of\n",
            "    characters\n",
            "    in a line\n",
            "    before\n",
            "    breaking\n",
            "    the line\n",
            "    (default:\n",
            "    None)\n",
            "  --max_line_count MAX_LINE_COUNT\n",
            "    (requires -\n",
            "    -word_times\n",
            "    tamps True)\n",
            "    the maximum\n",
            "    number of\n",
            "    lines in a\n",
            "    segment\n",
            "    (default:\n",
            "    None)\n",
            "  --threads THREADS\n",
            "    number of\n",
            "    threads\n",
            "    used by\n",
            "    torch for\n",
            "    CPU\n",
            "    inference;\n",
            "    supercedes \n",
            "    MKL_NUM_THR\n",
            "    EADS/OMP_NU\n",
            "    M_THREADS\n",
            "    (default:\n",
            "    0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "51Doi2smX6Ta"
      }
    }
  ]
}